{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please **submit this Jupyter notebook through Canvas** no later than **Monday November 4, 8:59**, before the start of the lecture.\n",
    "\n",
    "Homework is in **groups of two**, and you are expected to hand in original work. Work that is copied from another group will not be accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Exercise 0\n",
    "In the box below, write down the names + student ID of the people in your group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name1: Wiebe Jelsma <br>\n",
    "Name2: Julien Fer <br>\n",
    "Student_number1: 12468223 <br>\n",
    "Student_number2: 10649441 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Exercise 1\n",
    "This exercise is a variant of exercise 1.6 in the book.\n",
    "\n",
    "## (a) \n",
    "Lookup the Taylor series for $\\cos(x)$.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _<font size=2>(You don't have to hand in the series expansion)</font>_\n",
    "## (b)\n",
    "What are the forward and backward errors if we approximate $\\cos(x)$ by the first **two** nonzero terms in the Taylor series at $x = 0.2$, $x = 1.0$ and $x = 2.0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward error of x = 0.2 is  -6.657784124164401e-05\n",
      "Forward error of x = 1 is  -0.040302305868139765\n",
      "Forward error of x = 2 is  -0.5838531634528576\n",
      "Backward error of x = 0.2 is  0.00033484232311967177\n",
      "Backward error of x = 1 is  0.04719755119659785\n",
      "Backward error of x = 2 is  1.1415926535897931\n"
     ]
    }
   ],
   "source": [
    "def two_non_zero(x):\n",
    "    y = 1-(x**2/2)\n",
    "    return y\n",
    "\n",
    "x1 = 0.2\n",
    "x2 = 1\n",
    "x3 = 2\n",
    "\n",
    "FE_0 = two_non_zero(x1) - np.cos(0.2)\n",
    "FE_1 = two_non_zero(x2) - np.cos(1)\n",
    "FE_2 = two_non_zero(x3) - np.cos(2)\n",
    "print(\"Forward error of x = 0.2 is \", FE_0)\n",
    "print(\"Forward error of x = 1 is \", FE_1)\n",
    "print(\"Forward error of x = 2 is \", FE_2)\n",
    "\n",
    "BE_0 = np.arccos(two_non_zero(x1)) - x1\n",
    "BE_1 = np.arccos(two_non_zero(x2)) - x2\n",
    "BE_2 = np.arccos(two_non_zero(x3)) - x3\n",
    "print(\"Backward error of x = 0.2 is \", BE_0)\n",
    "print(\"Backward error of x = 1 is \", BE_1)\n",
    "print(\"Backward error of x = 2 is \", BE_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer, using $\\LaTeX$, in this box. <br>\n",
    "Pay attention, there might be rounding errors! We choose to display the first 4 digits, because the book chose the same.\n",
    "We made use of the Maclaurin series, so we assume a = 0. \n",
    "### Taylor series:\n",
    "\n",
    "Taylor series for cos(x):\n",
    "$1-\\frac{x^2}{2!} + \\frac{x^4}{4!} - ... + \\frac{x^n}{n!}$\n",
    "For the first two nonzero terms we use $1-\\frac{x^2}{2!}$ <br>\n",
    "When x = 0.2, this will give us: <br>\n",
    "$1 - \\frac{0.2^2}{2}$ which results in 0.98. <br>\n",
    "When x is 1, this gives $1 - \\frac{1^2}{2}$ which results in 0.5 and x = 2 gives us \n",
    "$1 - \\frac{2^2}{2}$ which results in -1.<br>\n",
    "### Forward erros:\n",
    "\n",
    "The real value of $cos(0.2) = 9.8001e^{-1}$, $cos(1) = 5.4030e^{-1}$ and $cos(2) = -4.1615e^{-1}$. \n",
    "The discrepancy between the computed and true values, $\\Delta y = \\hat{y} - y$, is called the forward error. \n",
    "\n",
    "For $x = 0.2$, we see that the forward error is $0.98 - cos(0.2) = -6.6578e^{-5}$.<br>\n",
    "For $x = 1$ we will see a forward error of $0.5 - cos(1) = -4.0302e^{-2}$. <br>\n",
    "$x = 2$ we find $-1 - cos(2) = -5.8385e^{-1}$. We see that the forward error gets bigger when x becomes bigger. <br> \n",
    "### Backward errors:\n",
    "\n",
    "We can find the backwards error with arccos. You have to take the arcoss of the value you found. For $x = 1:$\n",
    "we take the arccos of the value we found. We filled in $1 - \\frac{1^2}{2}$ which leads to 0.5. We then take the arccos of 0.5, which is 1.0472. We then subtract x, so 1. We find $arccos(0.5) - 1 = 4.7198e^{-2}$. <br>\n",
    "For $x = 0.2$, we found $1 - \\frac{0.2^2}{2}$ which is 0.98. We take arccos of 0.98, which is 0.2003. We find $arccos(0.98) - 0.2 = 3.3484e^{-4}$. <rb>\n",
    "Now $x = 2$. We found that value -1. Arccos of -1 is 3.1416, thus the backward error of $x = 2$ is calculated by $arccos(-1) - 2 = 1.1416$.\n",
    "<br>\n",
    "### Summary:\n",
    "x | forward error | backward error\n",
    ":-- | :-: | --:\n",
    "0.2 | -6.6578$e^{-5}$ | 3.3484$e^{-4}$\n",
    "1 | -4.0302$e^{-2}$ | 4.7198$e^{-2}$\n",
    "2 | -5.8385$e^{-1}$ | 1.1416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)\n",
    "What are the forward and backward errors if we approximate $\\cos(x)$ by the first **three** nonzero terms in the Taylor series at $x = 0.2$, $x = 1.0$ and $x = 2.0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward error of x = 0.2 is  8.882542501531532e-08\n",
      "Forward error of x = 1 is  0.0013643607985268646\n",
      "Forward error of x = 2 is  0.08281350321380904\n",
      "Backward error of x = 0.2 is  -4.4710234142764094e-07\n",
      "Backward error of x = 1 is  -0.0016222452979235413\n",
      "Backward error of x = 2 is  -0.0893667637509814\n"
     ]
    }
   ],
   "source": [
    "def three_non_zero(x):\n",
    "    y = 1-(x**2/2)+(x**4/(24))\n",
    "    return y\n",
    "FE_0_3 = three_non_zero(x1) - np.cos(0.2)\n",
    "FE_1_3 = three_non_zero(x2) - np.cos(1)\n",
    "FE_2_3 = three_non_zero(x3) - np.cos(2)\n",
    "print(\"Forward error of x = 0.2 is \", FE_0_3)\n",
    "print(\"Forward error of x = 1 is \", FE_1_3)\n",
    "print(\"Forward error of x = 2 is \", FE_2_3)\n",
    "\n",
    "BE_0_3 = np.arccos(three_non_zero(x1)) - x1\n",
    "BE_1_3 = np.arccos(three_non_zero(x2)) - x2\n",
    "BE_2_3 = np.arccos(three_non_zero(x3)) - x3\n",
    "print(\"Backward error of x = 0.2 is \", BE_0_3)\n",
    "print(\"Backward error of x = 1 is \", BE_1_3)\n",
    "print(\"Backward error of x = 2 is \", BE_2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer, using $\\LaTeX$, in this box.\n",
    "### Taylor series:\n",
    "Taylor series for cos(x) with three nonzero is: <br>\n",
    "$1-\\frac{x^2}{2!} + \\frac{x^4}{4!}$ <br>\n",
    "When x = 0.2 we get $1-\\frac{0.2^2}{2!} + \\frac{0.2^4}{4!}$ we get $9.8007e^{-1}$. <br>\n",
    "For x = 1 we find $5.4167e^{-1}$ and for x = 2 we get $-3.3333e^{-1}$ <br>\n",
    "### Forward error: \n",
    "\n",
    "$x = 0.2: $ will lead to $9.8007e^{-1} - cos(0.2) = 8.8819e^{-8}$, <br> $x = 1$ gives $5.4167e^{-1} - cos(1) = 1.3644e^{-3}$ and <br>$x = 2$ results in $-\\frac{1}{3}$ $- cos(2) = 8.2814e^{-2}$. <br>Just like we saw in 1.B, the forward errors become lower when x becomes lower as well. <br>\n",
    "### Backward error\n",
    "$x = 0.2:$ <br>\n",
    "The value we found was $9.8007e^{-1}$, we use this for arccos.  <br>\n",
    "$arccos(9.8007e^{-1}) - 0.2 =  -1.683e^{-4}$\n",
    "<br>\n",
    "$x = 1:$ the value we found was $5.4167e^{-1}$, we use this for arccos. This gives: 0.9983381. <br>\n",
    "$arccos(5.4167e^{-1}) - 1 = -1.6222e^{-3}$\n",
    "<br>\n",
    "$x = 2:$ the value we found was -1/3, we use this for arccos. This gives: 1.91063324. <br>\n",
    "$arccos(-1/3) - 2 = -8.9367e^{-2}$\n",
    "\n",
    "\n",
    "### Summary:\n",
    "x | forward error | backward error\n",
    ":-- | :-: | --:\n",
    "0.2 | 8.8819$e^{-8}$ | -4.47$e^{-7}$\n",
    "1 | 1.3644$e^{-3}$ | -1.6222$e^{-3}$\n",
    "2 | 8.2814$e^{-2}$ | -8.9367$e^{-2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)\n",
    "Compute the relative condition of $x \\mapsto \\cos(x)$ at $x = 0.2$, $x=1.0$ and $x=2.0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 2 non-zero:\n",
    "(forward error/y) / (backward error / x)\n",
    "##### $x = 0.2$:\n",
    "$ \\frac{\\frac{-6.6578e^{-5}}{cos(0.2)}} {\\frac{3.3484e^{-4}}{0.2}} = -4.0576e^{-2}$\n",
    "##### $x = 1$:\n",
    "$ \\frac{\\frac{-4.0302e^{-2}}{cos(1)}} {\\frac{4.7198e^{-2}}{1}} = -1.5804$\n",
    "##### $x = 2$:\n",
    "\n",
    "$ \\frac{\\frac{-5.8385e^{-1}}{cos(2)}} {\\frac{1.1416}{2}} = 2.4579$\n",
    "\n",
    "### For 3 non-zero:\n",
    "##### $x = 0.2$:\n",
    "$\\frac{\\frac{8.8819e^{-8}}{cos(0.2)}} {\\frac{-4.47e^{-7}}{0.2}} = -4.0548e^{-2}$\n",
    "##### $x = 1$:\n",
    "$\\frac{\\frac{1.3644e^{-3}}{cos(1)}} {\\frac{-1.6222e^{-3}}{1}} = -1.5567$\n",
    "##### $x = 2$:\n",
    "$\\frac{\\frac{8.2814e^{-2}}{cos(2)}} {\\frac{-8.9367e^{-2}}{2}} = 4.4536$\n",
    "\n",
    "### Summary:\n",
    "x | 2 non-zero | 3 non-zero\n",
    ":-- | :-: | --:\n",
    "0.2 | $-4.0576e^{-2}$ | $-4.0548e^{-2}$\n",
    "1 | -1.5804 | -1.5567\n",
    "2 | 2.4579 | 4.4536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Exercise 2\n",
    "This is computer exercise 1.16 from the book.\n",
    "\n",
    "Write a program that sums $n$ random, **single-precision** floating-point numbers $x_i$, uniformly distributed on the interval $[0,1]$. Sum the numbers in each of the following ways (use only single-precision floating-point variables unless specifically indicated otherwise).\n",
    "\n",
    "## (a)\n",
    "Sum the numbers in the order in which they were generated, using a double-precision variable in which to accumulate the sum.\n",
    "\n",
    "Put your solution code in the box below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_double_precision_normal(numbers):\n",
    "    \"\"\"\n",
    "    For a given amount (n) of numbers random single-precision floating-point numbers are generated and summed. \n",
    "    The summation is in double-precision and in the order of the genreated numbers.\n",
    "    \"\"\"\n",
    "    \n",
    "    total = np.float64(0.0)\n",
    "    for number in numbers:\n",
    "        total += number\n",
    "        \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) \n",
    "Sum the numbers in the order in which they were generated, this time using a single-precision accumulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_single_precision_normal(numbers):\n",
    "    \"\"\"\n",
    "    For a given amount (n) of numbers random single-precision floating-point numbers are generated and summed. \n",
    "    The summation is in single-precision and in the order of the genreated numbers.\n",
    "    \"\"\"\n",
    "    \n",
    "    total = np.float32(0.0)\n",
    "    for number in numbers:\n",
    "        total += number\n",
    "        \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)\n",
    "Use the following _compensated summation_ algorithm (due to Kahan), again using only single precision, to sum the numbers in the order in which they were generated:\n",
    "\n",
    "$\n",
    "s = x_1\\\\\n",
    "c = 0\\\\\n",
    "\\textbf{for } i = 2 \\textbf{ to } n\\\\\n",
    "\\quad y = x_i - c\\\\\n",
    "\\quad t = s+y\\\\\n",
    "\\quad c = (t-s) - y\\\\\n",
    "\\quad s = t\\\\\n",
    "\\textbf{end}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_sum_normal(numbers):\n",
    "    \"\"\"\n",
    "    Compensated summation algorithm (Kahan) in the order in which they were genretaded\n",
    "    \"\"\"\n",
    "    \n",
    "    total = numbers[0]\n",
    "    c = np.float32(0.0)\n",
    "    \n",
    "    for i in range(1, len(numbers)):\n",
    "        y = numbers[i] - c\n",
    "        t = total + y\n",
    "        c = (t - total) - y\n",
    "        total = t\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) \n",
    "Sum the numbers in order of increasing magnitude (this will require that the numbers be sorted\n",
    "before summing, for which you may use a library sorting routine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_single_precision_increasing(numbers):\n",
    "    \"\"\"\n",
    "    For a given amount (n) of numbers random single-precision floating-point numbers are generated and summed. \n",
    "    The summation is in single-precision and in increasing order.\n",
    "    \"\"\"\n",
    "    \n",
    "    sorted_numbers = np.sort(numbers)\n",
    "    total = np.float32(0.0)\n",
    "    for number in sorted_numbers:\n",
    "        total += number\n",
    "        \n",
    "    return total\n",
    "\n",
    "def comp_sum_increasing(numbers):\n",
    "    \"\"\"\n",
    "    Compensated summation algorithm (Kahan) in the increasing order.\n",
    "    \"\"\"\n",
    "    \n",
    "    sorted_numbers = np.sort(numbers)\n",
    "    total = sorted_numbers[0]\n",
    "    c = np.float32(0.0)\n",
    "    \n",
    "    for i in range(1, len(sorted_numbers)):\n",
    "        y = sorted_numbers[i] - c\n",
    "        t = total + y\n",
    "        c = (t - total) - y\n",
    "        total = t\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) \n",
    "Sum the numbers in order of decreasing magnitude (i.e., reverse the order of summation from part (d))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_single_precision_decreasing(numbers):\n",
    "    \"\"\"\n",
    "    For a given amount (n) of numbers random single-precision floating-point numbers are generated and summed. \n",
    "    The summation is in single-precision and in decreasing order.\n",
    "    \"\"\"\n",
    "    \n",
    "    sorted_numbers = np.sort(numbers)[::-1]\n",
    "    total = np.float32(0.0)\n",
    "    for number in sorted_numbers:\n",
    "        total += number\n",
    "        \n",
    "    return total\n",
    "\n",
    "def comp_sum_decreasing(numbers):\n",
    "    \"\"\"\n",
    "    Compensated summation algorithm (Kahan) in the decreasing order.\n",
    "    \"\"\"\n",
    "    \n",
    "    sorted_numbers = np.sort(numbers)[::-1]\n",
    "    total = sorted_numbers[0]\n",
    "    c = np.float32(0.0)\n",
    "    \n",
    "    for i in range(1, len(sorted_numbers)):\n",
    "        y = sorted_numbers[i] - c\n",
    "        t = total + y\n",
    "        c = (t - total) - y\n",
    "        total = t\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f)\n",
    "\n",
    "Run your program for various values of $n$ and compare the results for methods (a) through (e). You may need to use a fairly large value for $n$ to see a substantial difference. How do the methods rank in terms of accuracy, and why? How do the methods compare in cost? Can you explain why the algorithm in part (c) works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer, using $\\LaTeX$, in this box.\n",
    "\n",
    "Tests are run for various values of $n:(10, 100, 1000, 10000, 100000, 1000000)$ (see code below). The differences with the summation found with the double-precision method of exercise a and the other methods are for small $n$ (less than 100) approximately the same, however, the compenated summation algorithm already manages to perform slightly more accurate that the other algorithms. Moreover, for a greater values of $n$ we note more significant effect:\n",
    "* The summation algorithm of exercise c (the compensted summation algrotihm) is in all cases the most accurate (similar to the summation of exercise a). It is even insensitive to the order of summation (given, increasing or decreasing) and always yields the same result. This is not the case for the basic summation algorithm. For the basic summation algorithm it seems most accurate to perform the summation with an increasing order of numbers. The summation performed with the given order is more accurate than the algorithm with decreasing magnitude. So the complete rank would be: (1) the compensated summation algorithm (exercise c, given/increasing/decreasing order); (2) basic summation algorithm (increasing order); (3) basic summation algorithm (given order); and finally (4) basic summation algorithm (decreasing order).\n",
    "* The compensated summation algorithm is the most time consuming of all. This makes sense as it contains the most elmentary operations of all. Furthermore, we note that the basic summation in increasing order is slower than performing the summation in decreasing order which in turn is slower than the basic summation in given order (might be to the fact that we need to sort the floating point numbers)\n",
    "\n",
    "The algorithm in part (c) works because it makes use of two different accumulators: total holds the sum and c accumulates the part not assimilated into total, to nudge the low-order part of total the next time around. Thus the summation proceeds with \"guard digits\" in c, which is better than not having any, but is not as good as performing the calculations with double the precision of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 10 random numbers betweeen 0 and 1\n",
      "\n",
      "Summation in given order (double precision): 5.705262541770935\n",
      "Summation in given order (single precision): 5.705262184143066 || Difference is: 3.5762786865234375e-07 || Time: 0.0\n",
      "Compensated sumation in given order: 5.705262660980225 || Difference is: -1.1920928955078125e-07 || Time: 0.0\n",
      "Summation in increasing order (single precision): 5.705262660980225 || Difference is: -1.1920928955078125e-07 || Time: 0.0\n",
      "Compensated summation in increasing order: 5.705262660980225 || Difference is: -1.1920928955078125e-07 || Time: 0.0\n",
      "Summation in decreasing order (single precision): 5.705262660980225 || Difference is: -1.1920928955078125e-07 || Time: 0.0\n",
      "Compensated summation in decreasing order: 5.705262660980225 || Difference is: -1.1920928955078125e-07 || Time: 0.0\n",
      "=============================================================================\n",
      "For 100 random numbers betweeen 0 and 1\n",
      "\n",
      "Summation in given order (double precision): 46.159665250452235\n",
      "Summation in given order (single precision): 46.15966796875 || Difference is: -2.718297764658928e-06 || Time: 0.0\n",
      "Compensated sumation in given order: 46.159664154052734 || Difference is: 1.096399500966072e-06 || Time: 0.0\n",
      "Summation in increasing order (single precision): 46.15966796875 || Difference is: -2.718297764658928e-06 || Time: 0.0\n",
      "Compensated summation in increasing order: 46.159664154052734 || Difference is: 1.096399500966072e-06 || Time: 0.0\n",
      "Summation in decreasing order (single precision): 46.15965270996094 || Difference is: 1.2540491297841072e-05 || Time: 0.0\n",
      "Compensated summation in decreasing order: 46.159664154052734 || Difference is: 1.096399500966072e-06 || Time: 0.0\n",
      "=============================================================================\n",
      "For 1000 random numbers betweeen 0 and 1\n",
      "\n",
      "Summation in given order (double precision): 520.2578267883509\n",
      "Summation in given order (single precision): 520.257568359375 || Difference is: 0.00025842897593975067 || Time: 0.0\n",
      "Compensated sumation in given order: 520.2578125 || Difference is: 1.4288350939750671e-05 || Time: 0.0\n",
      "Summation in increasing order (single precision): 520.2579345703125 || Difference is: -0.00010778196156024933 || Time: 0.0\n",
      "Compensated summation in increasing order: 520.2578125 || Difference is: 1.4288350939750671e-05 || Time: 0.0\n",
      "Summation in decreasing order (single precision): 520.257568359375 || Difference is: 0.00025842897593975067 || Time: 0.0\n",
      "Compensated summation in decreasing order: 520.2578125 || Difference is: 1.4288350939750671e-05 || Time: 0.004000425338745117\n",
      "=============================================================================\n",
      "For 10000 random numbers betweeen 0 and 1\n",
      "\n",
      "Summation in given order (double precision): 4998.609639293067\n",
      "Summation in given order (single precision): 4998.62060546875 || Difference is: -0.010966175683279289 || Time: 0.0039980411529541016\n",
      "Compensated sumation in given order: 4998.60986328125 || Difference is: -0.00022398818327928893 || Time: 0.004010200500488281\n",
      "Summation in increasing order (single precision): 4998.6171875 || Difference is: -0.007548206933279289 || Time: 0.0040051937103271484\n",
      "Compensated summation in increasing order: 4998.60986328125 || Difference is: -0.00022398818327928893 || Time: 0.00798940658569336\n",
      "Summation in decreasing order (single precision): 4998.58837890625 || Difference is: 0.02126038681672071 || Time: 0.004006385803222656\n",
      "Compensated summation in decreasing order: 4998.60986328125 || Difference is: -0.00022398818327928893 || Time: 0.011999130249023438\n",
      "=============================================================================\n",
      "For 100000 random numbers betweeen 0 and 1\n",
      "\n",
      "Summation in given order (double precision): 50180.501163632725\n",
      "Summation in given order (single precision): 50180.62890625 || Difference is: -0.12774261727463454 || Time: 0.024007320404052734\n",
      "Compensated sumation in given order: 50180.5 || Difference is: 0.00116363272536546 || Time: 0.06401300430297852\n",
      "Summation in increasing order (single precision): 50180.40625 || Difference is: 0.09491363272536546 || Time: 0.03611421585083008\n",
      "Compensated summation in increasing order: 50180.5 || Difference is: 0.00116363272536546 || Time: 0.08392333984375\n",
      "Summation in decreasing order (single precision): 50180.54296875 || Difference is: -0.04180511727463454 || Time: 0.032004594802856445\n",
      "Compensated summation in decreasing order: 50180.5 || Difference is: 0.00116363272536546 || Time: 0.0760190486907959\n",
      "=============================================================================\n",
      "For 1000000 random numbers betweeen 0 and 1\n",
      "\n",
      "Summation in given order (double precision): 500092.09252776194\n",
      "Summation in given order (single precision): 500108.25 || Difference is: -16.15747223806102 || Time: 0.20804619789123535\n",
      "Compensated sumation in given order: 500092.09375 || Difference is: -0.0012222380610182881 || Time: 0.6561810970306396\n",
      "Summation in increasing order (single precision): 500095.84375 || Difference is: -3.7512222380610183 || Time: 0.46421194076538086\n",
      "Compensated summation in increasing order: 500092.09375 || Difference is: -0.0012222380610182881 || Time: 0.8099009990692139\n",
      "Summation in decreasing order (single precision): 500099.28125 || Difference is: -7.188722238061018 || Time: 0.3750276565551758\n",
      "Compensated summation in decreasing order: 500092.09375 || Difference is: -0.0012222380610182881 || Time: 0.796928882598877\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "N = [10 ** i for i in range(1, 7)]\n",
    "\n",
    "for amount in N:\n",
    "    values = np.random.uniform(0, np.nextafter(1, 2), amount).astype(\"float32\")\n",
    "    total1 = sum_double_precision_normal(values)\n",
    "    \n",
    "    start = time.time()\n",
    "    total2 = sum_single_precision_normal(values)\n",
    "    end2 = time.time() - start\n",
    "    diff2 = total1 - total2\n",
    "    \n",
    "    start = time.time()\n",
    "    total3 = comp_sum_normal(values)\n",
    "    end3 = time.time() - start\n",
    "    diff3 = total1 - total3\n",
    "    \n",
    "    start = time.time()\n",
    "    total4 = sum_single_precision_increasing(values)\n",
    "    end4 = time.time() - start\n",
    "    diff4 = total1 - total4\n",
    "    \n",
    "    start = time.time()\n",
    "    total5 = comp_sum_increasing(values)\n",
    "    end5 = time.time() - start\n",
    "    diff5 = total1 - total5\n",
    "    \n",
    "    start = time.time()\n",
    "    total6 = sum_single_precision_decreasing(values)\n",
    "    end6 = time.time() - start\n",
    "    diff6 = total1 - total6\n",
    "    \n",
    "    start = time.time()\n",
    "    total7 = comp_sum_decreasing(values)\n",
    "    end7 = time.time() - start\n",
    "    diff7 = total1 - total7\n",
    "    \n",
    "    print(f\"For {amount} random numbers betweeen 0 and 1\")\n",
    "    print()\n",
    "    print(f\"Summation in given order (double precision): {total1}\")\n",
    "    print(f\"Summation in given order (single precision): {total2} || Difference is: {diff2} || Time: {end2}\")\n",
    "    print(f\"Compensated sumation in given order: {total3} || Difference is: {diff3} || Time: {end3}\")\n",
    "    print(f\"Summation in increasing order (single precision): {total4} || Difference is: {diff4} || Time: {end4}\")\n",
    "    print(f\"Compensated summation in increasing order: {total5} || Difference is: {diff5} || Time: {end5}\")\n",
    "    print(f\"Summation in decreasing order (single precision): {total6} || Difference is: {diff6} || Time: {end6}\")\n",
    "    print(f\"Compensated summation in decreasing order: {total7} || Difference is: {diff7} || Time: {end7}\")\n",
    "    print(\"=============================================================================\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
